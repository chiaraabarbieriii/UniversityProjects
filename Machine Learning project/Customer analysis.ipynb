{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer analysis\n",
    "\n",
    "The intent of this project is to be able to successfully apply classification and clustering on a dataset and be able to analyze and make predictions that are relevant to the goal predefined.\n",
    "\n",
    "For this project I have chosen a dataset which collects the data that is necessary to analyse a customer behavior when making a purchase within a company, so a *Customer Personality Analysis*.\n",
    "\n",
    "The link to find the dataset that was used is:\n",
    "https://www.kaggle.com/datasets/imakash3011/customer-personality-analysis\n",
    "\n",
    "## Goals\n",
    "The goal of this project is to:\n",
    "1. Predict whether offers are an effective method to have a client buy in the store - We will be doing this by using binary classification of the attribute \"Response\", since it tells us whether a customer accepted the offer (1) or refused (0) - classify features values in 1 or 0. It is done in this notebook.\n",
    "2. Segment customers based on their characteristics such as age, income, family situation... -  We will identify distinct customer groups that may have different needs and behaviors by applying clustering techniques. Look at the notebook \"Clustering\" - We will first segment customers based on all the characteristics given by the dataset and afterwards we will only consider their spending habits and Income to segregate them.\n",
    "\n",
    "## Attributes\n",
    "In this dataset the attributes are divided into four different types of categories\n",
    "\n",
    "**People**\n",
    "- ID: Customer's unique identifier\n",
    "- Year_Birth: Customer's birth year\n",
    "- Education: Customer's education level\n",
    "- Marital_Status: Customer's marital status\n",
    "- Income: Customer's yearly household income\n",
    "- Kidhome: Number of children in customer's household\n",
    "- Teenhome: Number of teenagers in customer's household\n",
    "- Dt_Customer: Date of customer's enrollment with the company\n",
    "- Recency: Number of days since customer's last purchase\n",
    "- Complain: 1 if the customer complained in the last 2 years, 0 otherwise\n",
    "\n",
    "**Products**\n",
    "- MntWines: Amount spent on wine in last 2 years\n",
    "- MntFruits: Amount spent on fruits in last 2 years\n",
    "- MntMeatProducts: Amount spent on meat in last 2 years\n",
    "- MntFishProducts: Amount spent on fish in last 2 years\n",
    "- MntSweetProducts: Amount spent on sweets in last 2 years\n",
    "- MntGoldProds: Amount spent on gold in last 2 years\n",
    "\n",
    "**Promotions**\n",
    "- NumDealsPurchases: Number of purchases made with a discount\n",
    "- AcceptedCmp1: 1 if customer accepted the offer in the 1st campaign, 0 otherwise\n",
    "- AcceptedCmp2: 1 if customer accepted the offer in the 2nd campaign, 0 otherwise\n",
    "- AcceptedCmp3: 1 if customer accepted the offer in the 3rd campaign, 0 otherwise\n",
    "- AcceptedCmp4: 1 if customer accepted the offer in the 4th campaign, 0 otherwise\n",
    "- AcceptedCmp5: 1 if customer accepted the offer in the 5th campaign, 0 otherwise\n",
    "- Response: 1 if customer accepted the offer in the last campaign, 0 otherwise\n",
    "\n",
    "**Place of purchase**\n",
    "- NumWebPurchases: Number of purchases made through the company’s website\n",
    "- NumCatalogPurchases: Number of purchases made using a catalogue\n",
    "- NumStorePurchases: Number of purchases made directly in stores\n",
    "- NumWebVisitsMonth: Number of visits to company’s website in the last month\n",
    "\n",
    "The meaning of the attributes was copied from the presentation of the dataset, this presentation can be found in the link given above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries needed for the project\n",
    "In order to develop this project, these libraries are needed (some of the libraries were not used and just added during the development of the project):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic necessary libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from mlxtend.plotting import plot_decision_regions\n",
    "import mglearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the analysis of the dataset\n",
    "import pandas as pd\n",
    "import missingno as msno\n",
    "\n",
    "# For preprocessing\n",
    "import sklearn\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MaxAbsScaler, OrdinalEncoder, StandardScaler, KBinsDiscretizer, add_dummy_feature, LabelEncoder, Binarizer\n",
    "from sklearn.preprocessing import KBinsDiscretizer, add_dummy_feature, LabelEncoder, Binarizer, Normalizer, MinMaxScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# For splitting in train and test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#----------------------------------------------------------------------------------------------------------------------------------------------\n",
    "# We added all possible methods of libraries to facilitate model selection\n",
    "\n",
    "# Classifiers - Supervised learning\n",
    "from sklearn.linear_model import Perceptron, LogisticRegression, LinearRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor # Decision Tree, even if I will probably only use the classification Decision Tree\n",
    "from sklearn.svm import LinearSVC, SVC # Support Vector Machine\n",
    "from sklearn.decomposition import PCA # Dimensionality reduction feature extraction\n",
    "\n",
    "# Classifier - Unsupervised learning\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA # Dimensionality reduction feature extraction\n",
    "from mlxtend.feature_selection import SequentialFeatureSelector as SFS # Dimensionality reduction feature selection\n",
    "\n",
    "# To deal with imbalanced classes\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler, TomekLinks\n",
    "\n",
    "# Model selection\n",
    "from sklearn.experimental import enable_halving_search_cv\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, GridSearchCV, RandomizedSearchCV, cross_validate, RepeatedStratifiedKFold, HalvingGridSearchCV, HalvingRandomSearchCV\n",
    "from sklearn.model_selection import cross_val_predict, RepeatedKFold, ShuffleSplit, StratifiedShuffleSplit, learning_curve, validation_curve, cross_val_score\n",
    "from random import choice\n",
    "import itertools\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "\n",
    "# Ensemble learning\n",
    "from sklearn.ensemble import VotingClassifier, BaggingClassifier, RandomForestClassifier, RandomForestRegressor, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Model performance evaluation\n",
    "from sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, matthews_corrcoef, roc_curve, get_scorer_names\n",
    "from sklearn.metrics import precision_score, accuracy_score, recall_score,  precision_recall_curve\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# For the refinement of the model selection\n",
    "from scipy.stats import loguniform, beta, uniform\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset analysis\n",
    "\n",
    "To import the dataset we have to use Pandas library, since it allows to visualize the dataset and act upon it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>MntWines</th>\n",
       "      <th>...</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5524</td>\n",
       "      <td>1957</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>04-09-2012</td>\n",
       "      <td>58</td>\n",
       "      <td>635</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2174</td>\n",
       "      <td>1954</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>08-03-2014</td>\n",
       "      <td>38</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4141</td>\n",
       "      <td>1965</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21-08-2013</td>\n",
       "      <td>26</td>\n",
       "      <td>426</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6182</td>\n",
       "      <td>1984</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>10-02-2014</td>\n",
       "      <td>26</td>\n",
       "      <td>11</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5324</td>\n",
       "      <td>1981</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19-01-2014</td>\n",
       "      <td>94</td>\n",
       "      <td>173</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2235</th>\n",
       "      <td>10870</td>\n",
       "      <td>1967</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Married</td>\n",
       "      <td>61223.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>13-06-2013</td>\n",
       "      <td>46</td>\n",
       "      <td>709</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2236</th>\n",
       "      <td>4001</td>\n",
       "      <td>1946</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Together</td>\n",
       "      <td>64014.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>10-06-2014</td>\n",
       "      <td>56</td>\n",
       "      <td>406</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2237</th>\n",
       "      <td>7270</td>\n",
       "      <td>1981</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>56981.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25-01-2014</td>\n",
       "      <td>91</td>\n",
       "      <td>908</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2238</th>\n",
       "      <td>8235</td>\n",
       "      <td>1956</td>\n",
       "      <td>Master</td>\n",
       "      <td>Together</td>\n",
       "      <td>69245.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>24-01-2014</td>\n",
       "      <td>8</td>\n",
       "      <td>428</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2239</th>\n",
       "      <td>9405</td>\n",
       "      <td>1954</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>52869.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15-10-2012</td>\n",
       "      <td>40</td>\n",
       "      <td>84</td>\n",
       "      <td>...</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2240 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         ID  Year_Birth   Education Marital_Status   Income  Kidhome  \\\n",
       "0      5524        1957  Graduation         Single  58138.0        0   \n",
       "1      2174        1954  Graduation         Single  46344.0        1   \n",
       "2      4141        1965  Graduation       Together  71613.0        0   \n",
       "3      6182        1984  Graduation       Together  26646.0        1   \n",
       "4      5324        1981         PhD        Married  58293.0        1   \n",
       "...     ...         ...         ...            ...      ...      ...   \n",
       "2235  10870        1967  Graduation        Married  61223.0        0   \n",
       "2236   4001        1946         PhD       Together  64014.0        2   \n",
       "2237   7270        1981  Graduation       Divorced  56981.0        0   \n",
       "2238   8235        1956      Master       Together  69245.0        0   \n",
       "2239   9405        1954         PhD        Married  52869.0        1   \n",
       "\n",
       "      Teenhome Dt_Customer  Recency  MntWines  ...  NumWebVisitsMonth  \\\n",
       "0            0  04-09-2012       58       635  ...                  7   \n",
       "1            1  08-03-2014       38        11  ...                  5   \n",
       "2            0  21-08-2013       26       426  ...                  4   \n",
       "3            0  10-02-2014       26        11  ...                  6   \n",
       "4            0  19-01-2014       94       173  ...                  5   \n",
       "...        ...         ...      ...       ...  ...                ...   \n",
       "2235         1  13-06-2013       46       709  ...                  5   \n",
       "2236         1  10-06-2014       56       406  ...                  7   \n",
       "2237         0  25-01-2014       91       908  ...                  6   \n",
       "2238         1  24-01-2014        8       428  ...                  3   \n",
       "2239         1  15-10-2012       40        84  ...                  7   \n",
       "\n",
       "      AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  \\\n",
       "0                0             0             0             0             0   \n",
       "1                0             0             0             0             0   \n",
       "2                0             0             0             0             0   \n",
       "3                0             0             0             0             0   \n",
       "4                0             0             0             0             0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2235             0             0             0             0             0   \n",
       "2236             0             0             0             1             0   \n",
       "2237             0             1             0             0             0   \n",
       "2238             0             0             0             0             0   \n",
       "2239             0             0             0             0             0   \n",
       "\n",
       "      Complain  Z_CostContact  Z_Revenue  Response  \n",
       "0            0              3         11         1  \n",
       "1            0              3         11         0  \n",
       "2            0              3         11         0  \n",
       "3            0              3         11         0  \n",
       "4            0              3         11         0  \n",
       "...        ...            ...        ...       ...  \n",
       "2235         0              3         11         0  \n",
       "2236         0              3         11         0  \n",
       "2237         0              3         11         0  \n",
       "2238         0              3         11         0  \n",
       "2239         0              3         11         1  \n",
       "\n",
       "[2240 rows x 29 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_marketing = pd.read_csv('marketing_campaign.csv', sep=\"\\t\")\n",
    "dataset_marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check the information about the dataset..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2240 entries, 0 to 2239\n",
      "Data columns (total 29 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ID                   2240 non-null   int64  \n",
      " 1   Year_Birth           2240 non-null   int64  \n",
      " 2   Education            2240 non-null   object \n",
      " 3   Marital_Status       2240 non-null   object \n",
      " 4   Income               2216 non-null   float64\n",
      " 5   Kidhome              2240 non-null   int64  \n",
      " 6   Teenhome             2240 non-null   int64  \n",
      " 7   Dt_Customer          2240 non-null   object \n",
      " 8   Recency              2240 non-null   int64  \n",
      " 9   MntWines             2240 non-null   int64  \n",
      " 10  MntFruits            2240 non-null   int64  \n",
      " 11  MntMeatProducts      2240 non-null   int64  \n",
      " 12  MntFishProducts      2240 non-null   int64  \n",
      " 13  MntSweetProducts     2240 non-null   int64  \n",
      " 14  MntGoldProds         2240 non-null   int64  \n",
      " 15  NumDealsPurchases    2240 non-null   int64  \n",
      " 16  NumWebPurchases      2240 non-null   int64  \n",
      " 17  NumCatalogPurchases  2240 non-null   int64  \n",
      " 18  NumStorePurchases    2240 non-null   int64  \n",
      " 19  NumWebVisitsMonth    2240 non-null   int64  \n",
      " 20  AcceptedCmp3         2240 non-null   int64  \n",
      " 21  AcceptedCmp4         2240 non-null   int64  \n",
      " 22  AcceptedCmp5         2240 non-null   int64  \n",
      " 23  AcceptedCmp1         2240 non-null   int64  \n",
      " 24  AcceptedCmp2         2240 non-null   int64  \n",
      " 25  Complain             2240 non-null   int64  \n",
      " 26  Z_CostContact        2240 non-null   int64  \n",
      " 27  Z_Revenue            2240 non-null   int64  \n",
      " 28  Response             2240 non-null   int64  \n",
      "dtypes: float64(1), int64(25), object(3)\n",
      "memory usage: 507.6+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_marketing.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and the specific number of null values that it has."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                      0\n",
       "Year_Birth              0\n",
       "Education               0\n",
       "Marital_Status          0\n",
       "Income                 24\n",
       "Kidhome                 0\n",
       "Teenhome                0\n",
       "Dt_Customer             0\n",
       "Recency                 0\n",
       "MntWines                0\n",
       "MntFruits               0\n",
       "MntMeatProducts         0\n",
       "MntFishProducts         0\n",
       "MntSweetProducts        0\n",
       "MntGoldProds            0\n",
       "NumDealsPurchases       0\n",
       "NumWebPurchases         0\n",
       "NumCatalogPurchases     0\n",
       "NumStorePurchases       0\n",
       "NumWebVisitsMonth       0\n",
       "AcceptedCmp3            0\n",
       "AcceptedCmp4            0\n",
       "AcceptedCmp5            0\n",
       "AcceptedCmp1            0\n",
       "AcceptedCmp2            0\n",
       "Complain                0\n",
       "Z_CostContact           0\n",
       "Z_Revenue               0\n",
       "Response                0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_marketing.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the information about the dataset we find that it is almost perfectly clean (we only have few missing values in the column of the attribute Income), but for the aim of the project we will produce some noise, so that we can then apply different data-preprocessing methods.\n",
    "\n",
    "Now, we corrupt the dataset in the notebook \"Noise in the dataset\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding noise to the dataset\n",
    "\n",
    "In this part of the project we will corrupt the dataset, so we will add missing values, so that we can then show that we have the competence of  dealing with missing data.\n",
    "\n",
    "After importing the necessary libraries and the dataset we decide what we want to do to the dataset in order to corrupt it.\n",
    "\n",
    "For the project we have decided to add missing values to the columns:\n",
    "- Recency\n",
    "- Kidhome\n",
    "- AcceptedCmp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add % of missing values to insert in the column\n",
    "def add_missing_columns(col, amount):\n",
    "    X = col.copy()\n",
    "    size = amount if amount >= 1 else int(len(X) * amount)\n",
    "    indexes = np.random.choice(len(X), size, replace = False )\n",
    "    X[indexes] = np.nan\n",
    "    return X\n",
    "\n",
    "dataset_marketing[\"Recency\"]=add_missing_columns(dataset_marketing[\"Recency\"], 0.1) # I want to add 10% of missing values\n",
    "dataset_marketing[\"Kidhome\"]=add_missing_columns(dataset_marketing[\"Kidhome\"], 0.15) # I want to add 15% of missing values\n",
    "dataset_marketing[\"AcceptedCmp4\"]=add_missing_columns(dataset_marketing[\"AcceptedCmp4\"], 30) # I want to add 30 missing values in the column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moreover I will insert 5% of missing values in the rows that we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add % of missing values to insert in the row\n",
    "def add_missing_rows(df, amount):\n",
    "    X = df.copy()\n",
    "    rows, cols = X.shape\n",
    "    size = amount if amount >= 1 else int(rows * amount)\n",
    "    indexes = np.random.choice(rows, size, replace = False ) + 0.5\n",
    "    for i in indexes:\n",
    "        X.loc[i] = np.full((cols,),np.nan)\n",
    "    X = X.sort_index().reset_index(drop=True)\n",
    "    return X\n",
    "\n",
    "dataset_marketing = add_missing_rows(dataset_marketing, 0.05) # added 5% of missing values in the existing rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we add enough missing values in a column to show that we are able to drop a column, action needed when said column has too many missing values to be dealt with - the same can be done with rows.\n",
    "\n",
    "We will be doing this to the columns \"Year_Birth\" and \"Dt_Customer\", since they are less relevant for the purpose of the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_marketing[\"Year_Birth\"] = add_missing_columns(dataset_marketing[\"Year_Birth\"], 0.45) # I want to add 45% of missing values\n",
    "dataset_marketing[\"Dt_Customer\"] = add_missing_columns(dataset_marketing[\"Dt_Customer\"], 0.50) # I want to add 50% of missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check the info of the dataset and see for ourselves that it is not a clean dataset anymore since we have a discrete amount of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2352 entries, 0 to 2351\n",
      "Data columns (total 29 columns):\n",
      " #   Column               Non-Null Count  Dtype  \n",
      "---  ------               --------------  -----  \n",
      " 0   ID                   2240 non-null   float64\n",
      " 1   Year_Birth           1227 non-null   float64\n",
      " 2   Education            2240 non-null   object \n",
      " 3   Marital_Status       2240 non-null   object \n",
      " 4   Income               2216 non-null   float64\n",
      " 5   Kidhome              1904 non-null   float64\n",
      " 6   Teenhome             2240 non-null   float64\n",
      " 7   Dt_Customer          1119 non-null   object \n",
      " 8   Recency              2016 non-null   float64\n",
      " 9   MntWines             2240 non-null   float64\n",
      " 10  MntFruits            2240 non-null   float64\n",
      " 11  MntMeatProducts      2240 non-null   float64\n",
      " 12  MntFishProducts      2240 non-null   float64\n",
      " 13  MntSweetProducts     2240 non-null   float64\n",
      " 14  MntGoldProds         2240 non-null   float64\n",
      " 15  NumDealsPurchases    2240 non-null   float64\n",
      " 16  NumWebPurchases      2240 non-null   float64\n",
      " 17  NumCatalogPurchases  2240 non-null   float64\n",
      " 18  NumStorePurchases    2240 non-null   float64\n",
      " 19  NumWebVisitsMonth    2240 non-null   float64\n",
      " 20  AcceptedCmp3         2240 non-null   float64\n",
      " 21  AcceptedCmp4         2210 non-null   float64\n",
      " 22  AcceptedCmp5         2240 non-null   float64\n",
      " 23  AcceptedCmp1         2240 non-null   float64\n",
      " 24  AcceptedCmp2         2240 non-null   float64\n",
      " 25  Complain             2240 non-null   float64\n",
      " 26  Z_CostContact        2240 non-null   float64\n",
      " 27  Z_Revenue            2240 non-null   float64\n",
      " 28  Response             2240 non-null   float64\n",
      "dtypes: float64(26), object(3)\n",
      "memory usage: 533.0+ KB\n"
     ]
    }
   ],
   "source": [
    "dataset_marketing.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                      112\n",
       "Year_Birth             1125\n",
       "Education               112\n",
       "Marital_Status          112\n",
       "Income                  136\n",
       "Kidhome                 448\n",
       "Teenhome                112\n",
       "Dt_Customer            1233\n",
       "Recency                 336\n",
       "MntWines                112\n",
       "MntFruits               112\n",
       "MntMeatProducts         112\n",
       "MntFishProducts         112\n",
       "MntSweetProducts        112\n",
       "MntGoldProds            112\n",
       "NumDealsPurchases       112\n",
       "NumWebPurchases         112\n",
       "NumCatalogPurchases     112\n",
       "NumStorePurchases       112\n",
       "NumWebVisitsMonth       112\n",
       "AcceptedCmp3            112\n",
       "AcceptedCmp4            142\n",
       "AcceptedCmp5            112\n",
       "AcceptedCmp1            112\n",
       "AcceptedCmp2            112\n",
       "Complain                112\n",
       "Z_CostContact           112\n",
       "Z_Revenue               112\n",
       "Response                112\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_marketing.isnull().sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we save the corrupted dataset as a csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_marketing.to_csv('marketing_corrupted.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: saved so that we don't have different datasets each time me run the project, since the rows are removed randomly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the new corrupted dataset\n",
    "\n",
    "The new corrupted dataset is:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>ID</th>\n",
       "      <th>Year_Birth</th>\n",
       "      <th>Education</th>\n",
       "      <th>Marital_Status</th>\n",
       "      <th>Income</th>\n",
       "      <th>Kidhome</th>\n",
       "      <th>Teenhome</th>\n",
       "      <th>Dt_Customer</th>\n",
       "      <th>Recency</th>\n",
       "      <th>...</th>\n",
       "      <th>NumWebVisitsMonth</th>\n",
       "      <th>AcceptedCmp3</th>\n",
       "      <th>AcceptedCmp4</th>\n",
       "      <th>AcceptedCmp5</th>\n",
       "      <th>AcceptedCmp1</th>\n",
       "      <th>AcceptedCmp2</th>\n",
       "      <th>Complain</th>\n",
       "      <th>Z_CostContact</th>\n",
       "      <th>Z_Revenue</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5524.0</td>\n",
       "      <td>1957.0</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>58138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>04-09-2012</td>\n",
       "      <td>58.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2174.0</td>\n",
       "      <td>1954.0</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Single</td>\n",
       "      <td>46344.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>4141.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>71613.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21-08-2013</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6182.0</td>\n",
       "      <td>1984.0</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Together</td>\n",
       "      <td>26646.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10-02-2014</td>\n",
       "      <td>26.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5324.0</td>\n",
       "      <td>1981.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>58293.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19-01-2014</td>\n",
       "      <td>94.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>2347</td>\n",
       "      <td>10870.0</td>\n",
       "      <td>1967.0</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Married</td>\n",
       "      <td>61223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13-06-2013</td>\n",
       "      <td>46.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>2348</td>\n",
       "      <td>4001.0</td>\n",
       "      <td>1946.0</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Together</td>\n",
       "      <td>64014.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2349</th>\n",
       "      <td>2349</td>\n",
       "      <td>7270.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Graduation</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>56981.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>91.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2350</th>\n",
       "      <td>2350</td>\n",
       "      <td>8235.0</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>Master</td>\n",
       "      <td>Together</td>\n",
       "      <td>69245.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24-01-2014</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2351</th>\n",
       "      <td>2351</td>\n",
       "      <td>9405.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PhD</td>\n",
       "      <td>Married</td>\n",
       "      <td>52869.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2352 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0       ID  Year_Birth   Education Marital_Status   Income  \\\n",
       "0              0   5524.0      1957.0  Graduation         Single  58138.0   \n",
       "1              1   2174.0      1954.0  Graduation         Single  46344.0   \n",
       "2              2   4141.0         NaN  Graduation       Together  71613.0   \n",
       "3              3   6182.0      1984.0  Graduation       Together  26646.0   \n",
       "4              4   5324.0      1981.0         PhD        Married  58293.0   \n",
       "...          ...      ...         ...         ...            ...      ...   \n",
       "2347        2347  10870.0      1967.0  Graduation        Married  61223.0   \n",
       "2348        2348   4001.0      1946.0         PhD       Together  64014.0   \n",
       "2349        2349   7270.0         NaN  Graduation       Divorced  56981.0   \n",
       "2350        2350   8235.0      1956.0      Master       Together  69245.0   \n",
       "2351        2351   9405.0         NaN         PhD        Married  52869.0   \n",
       "\n",
       "      Kidhome  Teenhome Dt_Customer  Recency  ...  NumWebVisitsMonth  \\\n",
       "0         0.0       0.0  04-09-2012     58.0  ...                7.0   \n",
       "1         1.0       1.0         NaN     38.0  ...                5.0   \n",
       "2         NaN       0.0  21-08-2013     26.0  ...                4.0   \n",
       "3         1.0       0.0  10-02-2014     26.0  ...                6.0   \n",
       "4         1.0       0.0  19-01-2014     94.0  ...                5.0   \n",
       "...       ...       ...         ...      ...  ...                ...   \n",
       "2347      0.0       1.0  13-06-2013     46.0  ...                5.0   \n",
       "2348      2.0       1.0         NaN      NaN  ...                7.0   \n",
       "2349      0.0       0.0         NaN     91.0  ...                6.0   \n",
       "2350      0.0       1.0  24-01-2014      8.0  ...                3.0   \n",
       "2351      1.0       1.0         NaN     40.0  ...                7.0   \n",
       "\n",
       "      AcceptedCmp3  AcceptedCmp4  AcceptedCmp5  AcceptedCmp1  AcceptedCmp2  \\\n",
       "0              0.0           0.0           0.0           0.0           0.0   \n",
       "1              0.0           0.0           0.0           0.0           0.0   \n",
       "2              0.0           0.0           0.0           0.0           0.0   \n",
       "3              0.0           0.0           0.0           0.0           0.0   \n",
       "4              0.0           0.0           0.0           0.0           0.0   \n",
       "...            ...           ...           ...           ...           ...   \n",
       "2347           0.0           0.0           0.0           0.0           0.0   \n",
       "2348           0.0           0.0           0.0           1.0           0.0   \n",
       "2349           0.0           1.0           0.0           0.0           0.0   \n",
       "2350           0.0           0.0           0.0           0.0           0.0   \n",
       "2351           0.0           0.0           0.0           0.0           0.0   \n",
       "\n",
       "      Complain  Z_CostContact  Z_Revenue  Response  \n",
       "0          0.0            3.0       11.0       1.0  \n",
       "1          0.0            3.0       11.0       0.0  \n",
       "2          0.0            3.0       11.0       0.0  \n",
       "3          0.0            3.0       11.0       0.0  \n",
       "4          0.0            3.0       11.0       0.0  \n",
       "...        ...            ...        ...       ...  \n",
       "2347       0.0            3.0       11.0       0.0  \n",
       "2348       0.0            3.0       11.0       0.0  \n",
       "2349       0.0            3.0       11.0       0.0  \n",
       "2350       0.0            3.0       11.0       0.0  \n",
       "2351       0.0            3.0       11.0       1.0  \n",
       "\n",
       "[2352 rows x 30 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_marketing= pd.read_csv('marketing_corrupted.csv', sep=\",\")\n",
    "dataset_marketing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we have missing values in all the columns present in the dataset as shown in the notebook where we have corrupted the dataset.\n",
    "We need to handle these missing values and then proceed with further analysis and modeling of data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
